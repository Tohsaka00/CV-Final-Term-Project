# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c56XaHBTl83mmIPmk7pMv7WNkNEXw6xd
"""

from google.colab import drive
drive.mount('/content/gdrive')

! pip install tensorflow_addons

import numpy as np
import pandas as pd
import os
import random
import matplotlib.pyplot as plt
import math
import tensorflow as tf 
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras import layers
from tensorflow.keras.optimizers import *
from tensorflow.keras.activations import *
from tensorflow.keras.losses import *
from tensorflow.keras.metrics import *
from tensorflow.keras.callbacks import *
from tensorflow.keras.utils import plot_model, to_categorical

import tensorflow_addons as tfa

import warnings
warnings.filterwarnings("ignore")
print(tf.test.is_gpu_available())
# setting seed

def set_seed(seed=42):
    random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)

set_seed()

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()
y_train = to_categorical(y_train)

#x_train = x_train.astype("float32") / 255.0
#x_test = x_test.astype("float32") / 255.0

#y_test = to_categorical(y_test)

AUTO = tf.data.AUTOTUNE
batch_size = 64

num_classes = 100
input_shape = (32, 32, 3)

print(f"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}")
print(f"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}")


# ambil secara manual 5000 data train terakhir ke data validation

train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_ds = train_ds.shuffle(1000).batch(batch_size).prefetch(AUTO)

val_ds = tf.data.Dataset.from_tensor_slices((x_train[45000:], y_train[45000:]))
val_ds = val_ds.batch(batch_size).prefetch(AUTO)

train_ds, val_ds

# Vit hyper parameters
patch_size = 8 # Size of the patches to be extracted from the input images.
image_size = 74 # resize image
num_patches = (image_size // patch_size) ** 2  # Number of patch
embedding_dim = 64 # Number of hidden units

dim_coefficient = 4
attention_dropout = 0.0
projection_dropout = 0.0
num_heads = 8 # attention heads
num_transformer_blocks = 8 # Number of repetitions of the transformer layer
mlp_dim = 256 # mlp units 

print(f"Patch size: {patch_size} X {patch_size} = {patch_size ** 2} ")
print(f"Patches per image: {num_patches}")


# make a image augmentation 

data_augmentation = Sequential(
    [
        layers.Normalization(),
        layers.Resizing(image_size, image_size),
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(factor=0.1),
        layers.RandomContrast(factor=0.1),
        layers.RandomZoom(height_factor=0.2, width_factor=0.2),
    ],
    name="data_augmentation",
)
# Compute the mean and the variance of the training data for normalization.
data_augmentation.layers[0].adapt(x_train)

#Menerapkan ekstraksi tambalan(PatchExtract) dan lapisan penyandian(PatchEmbedding) 

class PatchExtract(layers.Layer):
    def __init__(self, patch_size, **kwargs):
        super(PatchExtract, self).__init__(**kwargs)
        self.patch_size = patch_size

    def call(self, images):
        batch_size = tf.shape(images)[0]
        patches = tf.image.extract_patches(
            images=images,
            sizes=(1, self.patch_size, self.patch_size, 1),
            strides=(1, self.patch_size, self.patch_size, 1),
            rates=(1, 1, 1, 1),
            padding="VALID",
        )
        patch_dim = patches.shape[-1]
        patch_num = patches.shape[1]
        return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))


class PatchEmbedding(layers.Layer):
    def __init__(self, num_patch, embed_dim, **kwargs):
        super(PatchEmbedding, self).__init__(**kwargs)
        self.num_patch = num_patch
        self.proj = layers.Dense(embed_dim)
        self.pos_embed = layers.Embedding(input_dim=num_patch, output_dim=embed_dim)

    def call(self, patch):
        pos = tf.range(start=0, limit=self.num_patch, delta=1)
        return self.proj(patch) + self.pos_embed(pos)

plt.figure(figsize=(4, 4))
image = x_train[np.random.choice(range(x_train.shape[0]))]
plt.imshow(image.astype("uint8"))
plt.axis("off")

resized_image = tf.image.resize(
    tf.convert_to_tensor([image]), size=(image_size, image_size)
)
patches = PatchExtract(patch_size)(resized_image)
print(f"Image size: {image_size} X {image_size}")
print(f"Patch size: {patch_size} X {patch_size}")
print(f"Patches per image: {patches.shape[1]}")
print(f"Elements per patch: {patches.shape[-1]}")

n = int(np.sqrt(patches.shape[1]))
plt.figure(figsize=(4, 4))
for i, patch in enumerate(patches[0]):
    ax = plt.subplot(n, n, i + 1)
    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))
    plt.imshow(patch_img.numpy().astype("uint8"))
    plt.axis("off")

#Terapkan blok perhatian eksternal(external_attention) 

def external_attention(x, dim, num_heads, dim_coefficient=4, attention_dropout=0, projection_dropout=0):
    _, num_patch, channel = x.shape
    assert dim % num_heads == 0 # must return True
    num_heads = num_heads * dim_coefficient

    x = layers.Dense(dim * dim_coefficient)(x)
    # create tensor [batch_size, num_patches, num_heads, dim*dim_coefficient//num_heads]
    x = tf.reshape(
        x, shape=(-1, num_patch, num_heads, dim * dim_coefficient // num_heads)
    )
    x = tf.transpose(x, perm=[0, 2, 1, 3])
    # a linear layer M_k
    attn = layers.Dense(dim // dim_coefficient)(x)
    # normalize attention map
    attn = layers.Softmax(axis=2)(attn)
    # dobule-normalization
    attn = attn / (1e-9 + tf.reduce_sum(attn, axis=-1, keepdims=True))
    attn = layers.Dropout(attention_dropout)(attn)
    # a linear layer M_v

    x = layers.Dense(dim * dim_coefficient // num_heads)(attn)
    x = tf.transpose(x, perm=[0, 2, 1, 3])
    x = tf.reshape(x, [-1, num_patch, dim * dim_coefficient])
    # a linear layer to project original dim
    x = layers.Dense(dim)(x)
    x = layers.Dropout(projection_dropout)(x)
    return x


# mlp 1 layers dengan gelu(Gaussian Error Linear Unit) 

def mlp(x, embedding_dim, mlp_dim, drop_rate=0.0):
    x = layers.Dense(mlp_dim, activation=tfa.activations.gelu)(x)
    x = layers.Dropout(drop_rate)(x)
    x = layers.Dense(embedding_dim)(x)
    x = layers.Dropout(drop_rate)(x)
    return x

def transformer_encoder(
    x,
    embedding_dim,
    mlp_dim,
    num_heads,
    dim_coefficient,
    attention_dropout,
    projection_dropout,
    attention_type="external_attention",
):
    residual_1 = x
    x = layers.LayerNormalization(epsilon=1e-6)(x)
    if attention_type == "external_attention":
        x = external_attention(
            x,
            embedding_dim,
            num_heads,
            dim_coefficient,
            attention_dropout,
            projection_dropout,
        )
    elif attention_type == "self_attention":
        x = layers.MultiHeadAttention(
            num_heads=num_heads, key_dim=embedding_dim, dropout=attention_dropout
        )(x, x)
    x = layers.add([x, residual_1])
    residual_2 = x
    x = layers.LayerNormalization(epsilon=1e-6)(x)
    x = mlp(x, embedding_dim, mlp_dim)
    x = layers.add([x, residual_2])
    return x

def get_model(attention_type="external_attention"):
    inputs = layers.Input(shape=input_shape)
    # Image augment
    x = data_augmentation(inputs)
    # Extract patches.
    x = PatchExtract(patch_size)(x)
    # Create patch embedding.
    x = PatchEmbedding(num_patches, embedding_dim)(x)
    # Create Transformer block.
    for _ in range(num_transformer_blocks):
        x = transformer_encoder(
            x,
            embedding_dim,
            mlp_dim,
            num_heads,
            dim_coefficient,
            attention_dropout,
            projection_dropout,
            attention_type,
       ) 

    x = layers.GlobalAvgPool1D()(x)
    outputs = layers.Dense(num_classes, activation="softmax")(x)
    model = Model(inputs=inputs, outputs=outputs)
    return model

vit = get_model("self_attention")

vit.count_params() # total paramter dari vision transformer


# Hyperparamters for fit 

EPOCHS = 200
INIT_LR = 5e-3
MAX_LR = 5e-2
Wd = 1e-5


#define Callbacks
steps_per_epoch =  45000 // 256 # validation split 0.1

clr = tfa.optimizers.Triangular2CyclicalLearningRate(
    initial_learning_rate=INIT_LR,
    maximal_learning_rate=MAX_LR,
    step_size= 2 * steps_per_epoch
)

cb_checkpt = ModelCheckpoint("best.hdf5", monitor = 'val_loss', verbose = 0,
                                 save_best_only = True,
                                 save_weights_only = True,
                                 mode = 'min')

es = EarlyStopping(monitor="val_loss", patience=10, verbose=1, mode="min", restore_best_weights=True)


#define metrics
METRICS = [tf.keras.metrics.CategoricalAccuracy(name = "accuracy"),
           tf.keras.metrics.TopKCategoricalAccuracy(5, name= "top-5-accuracy")]
def scheduler(epoch):
    if epoch < 60:
        return 0.05
    if epoch < 120:
        return 0.01
    if epoch < 160:
        return 0.005
    return 0.001

#define optimizers 
ADAM = Adam(learning_rate=0.05)

SGD = tf.keras.optimizers.SGD(learning_rate=0.05, momentum=0.9) 

ADAMW = tfa.optimizers.AdamW(learning_rate = 0.05, weight_decay = Wd)

step = np.arange(0, EPOCHS * steps_per_epoch)
lr = clr(step)
plt.plot(step, lr)
plt.xlabel("Steps")
plt.ylabel("Learning Rate")
plt.title("Triangular2CyclicalLearningRate", size=20) 
plt.show()

# fit
vit.compile(optimizer = SGD,
            loss = "CategoricalCrossentropy", 
            metrics = METRICS)

history = vit.fit(train_ds, validation_data=val_ds,batch_size=256,
                  epochs = EPOCHS,callbacks = [cb_checkpt,LearningRateScheduler(scheduler), TensorBoard(log_dir='transformer_{:d}/'.format(num_transformer_blocks), histogram_freq=0)])
vit.summary()
_, accuracy, top_5_accuracy = vit.evaluate(val_ds)
print(f"Val accuracy: {round(accuracy * 100, 2)}%")
print(f"Val top 5 accuracy: {round(top_5_accuracy * 100, 2)}%")

## untuk data test(unseen)

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

y_predict = np.argmax(vit.predict(x_test), axis=1)

y_actual = y_test.copy()

print(f"Accuracy score: {accuracy_score(y_actual,y_predict)}")

confusion_matrix(y_actual,y_predict)

classification_report(y_actual, y_predict)

"""# 新段落"""